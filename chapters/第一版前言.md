下面是你提供的《**Preface to the First Edition（第一版序言）**》中文译文，保持学术与术语一致，可直接放到 GitHub：

---

# 第一版序言（Preface to the First Edition）

我们最初开始关注如今被称为**强化学习**的领域是在 1979 年底。当时我们都在马萨诸塞大学，参与了最早的一批项目之一，试图重振这样一种理念：**由类神经的自适应单元构成的网络**，可能成为通往人工自适应智能的一条有前景的道路。该项目探讨了 A. Harry Klopf 提出的**自适应系统的异稳态理论（heterostatic theory of adaptive systems）**。Harry 的工作蕴含着丰富的思想源泉，我们获准对这些思想进行批判性梳理，并与自适应系统漫长的既有研究史进行比较。我们的任务逐渐演变为：将这些想法加以分解，理解它们之间的关系与相对重要性。直到今天我们仍在做这件事。不过，早在 1979 年，我们就意识到，也许其中**最简单**、长期被理所当然接受的那个想法，从**计算**视角看反而极少受到关注——这就是**一个会“想要某种东西”的学习系统**：它会为了最大化来自环境的一种特殊信号而调整自身行为。这个想法可称为“**享乐式（hedonistic）**学习系统”，或者用今天的话说，便是**强化学习**的思想。

和许多人一样，我们最初以为强化学习早在控制论与人工智能的早期阶段就已被**深入探索**。但当我们更仔细地回看文献时却发现：它其实**只被粗浅地探索过**。尽管强化学习的思想确实激励了最早期的一些计算学习研究，但多数研究者随后转向了其他方向，比如**模式分类、监督学习、自适应控制**，或者干脆放弃了对“学习”的研究。其结果是，**如何从环境中“获得某种东西”**这一类学习所特有的问题，长期没有得到足够的重视。回过头看，重新聚焦于这一思想，正是促使这一研究分支启动的关键一步。在认识到这样一个**根本性**的思想尚未被充分探索之前，**关于强化学习的计算研究**难以取得实质性进展。

此后，该领域沿着若干方向不断发展、成熟。**强化学习**逐渐成为**机器学习、人工智能与神经网络**研究中最活跃的领域之一。该领域已经建立起坚实的**数学基础**并涌现出令人瞩目的**应用**。如今，对于强化学习的计算研究已蔚然成风，遍布全球的数百位活跃研究者来自**心理学、控制理论、人工智能与神经科学**等不同学科。尤其重要的是，人们系统地建立并深化了它与**最优控制理论**和**动态规划**之间的联系。

虽然要解决“**通过交互来实现目标的学习**”这一总体问题仍任重道远，但我们对它的理解已**显著提升**。我们现在可以在一个连贯的整体视角下，安放各个**组成性思想**——比如**时序差分学习（temporal-difference learning）**、**动态规划（dynamic programming）**与**函数逼近（function approximation）**——并理解它们相对于总体问题各自的位置。

我们写作本书的目标，是**清晰而简明**地阐述强化学习的**关键思想与算法**。我们希望本书对所有相关学科的读者都**易于理解**，但无法在书中对每一种学科视角都展开细致论述。总体而言，我们采用**人工智能与工程学**的视角。至于与其他领域的更深入联系，我们留待他书或他时。我们也选择不对强化学习做**严格的形式化**处理：既没有追求尽可能高的数学抽象层次，也没有采用“定理—证明”的写作体例。我们力图选取一种恰当的数学细节水平：既能为倾向数学化的读者**指明方向**，又不至于让数学形式**掩盖**底层思想的**简洁性与潜在普适性**。

某种意义上，我们为这本书已筹备了三十年，我们要感谢许多人。首先，要感谢那些帮助我们形成本书整体观点的人：
**Harry Klopf**——帮助我们意识到强化学习需要被重新唤起；
**Chris Watkins、Dimitri Bertsekas、John Tsitsiklis、Paul Werbos**——帮助我们看到其与动态规划的联系之价值；
**John Moore、Jim Kehoe**——在动物学习理论方面给予启发；
**Oliver Selfridge**——强调了“适应”的广度与重要性；
更广泛地，感谢在无数方面做出贡献的同事与学生：**Ron Williams、Charles Anderson、Satinder Singh、Sridhar Mahadevan、Steve Bradtke、Bob Crites、Peter Dayan、Leemon Baird**。
我们的视野也因与**Paul Cohen、Paul Utgoff、Martha Steenstrup、Gerry Tesauro、Mike Jordan、Leslie Kaelbling、Andrew Moore、Chris Atkeson、Tom Mitchell、Nils Nilsson、Stuart Russell、Tom Dietterich、Tom Dean、Bob Narendra**等的讨论而大大拓展。
感谢 **Michael Littman、Gerry Tesauro、Bob Crites、Satinder Singh、Wei Zhang** 分别提供了第 4.7、15.1、15.4、15.5、15.6 节的具体内容。
感谢 **美国空军科研办公室（AFOSR）**、**美国国家科学基金会（NSF）**与 **GTE Laboratories** 的长期且具有远见的支持。

我们也感谢许多曾审阅本书草稿并提出宝贵意见的人，包括：
**Tom Kalt、John Tsitsiklis、Pawel Cichosz、Olle Gällmo、Chuck Anderson、Stuart Russell、Ben Van Roy、Paul Steenstrup、Paul Cohen、Sridhar Mahadevan、Jette Randlov、Brian Sheppard、Thomas O’Connell、Richard Coggins、Cristina Versino、John H. Hiett、Andreas Badelt、Jay Ponte、Joe Beck、Justus Piater、Martha Steenstrup、Satinder Singh、Tommi Jaakkola、Dimitri Bertsekas、Torbjörn Ekman、Christina Björkman、Jakob Carlström、Olle Palmgren**。
最后，感谢 **Gwyn Mitchell** 在许多方面给予的帮助，以及 **Harry Stanton** 与 **Bob Prior** 作为我们在 **MIT Press** 的坚定支持者。

---

> 译者注：
>
> * “异稳态（heterostatic）”对应 Klopf 的理论术语，国内也有译作“变稳态”。
> * “享乐式（hedonistic）学习系统”指以最大化回报信号为目标的学习范式，是强化学习早期思想的表述之一。
> * 文中“时序差分学习、动态规划、函数逼近”是理解 RL 构成要素的三大支柱。

如果你需要，我可以把这段直接整理为 `chapters/preface_first_edition.md` 文件内容，同时附上一个最小的 `README` 进度徽章与术语表模板。
